<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>FOD Detection using Deep Learning</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link href="assets/stylesheets/main.css" rel="stylesheet">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
  <div class="container blog" id="first-content" style="background-color: #E0E4E6;">
    <div class="blog-title no-cover">
      <h1>FOD Detection using Deep Learning</h1>
      <h2>Final Year Thesis — CSA Format</h2>
      <p><strong>Author:</strong> Krishna Kumar</p>
      <p><strong>Advisor:</strong> Dr. XYZ</p>
    </div>
  </div>

  <div class="container blog">
    <h2>Abstract</h2>
    <p>
      This project proposes an automated Foreign Object Debris (FOD) detection framework using a multi-stage deep learning pipeline.
      Our approach improves upon prior methods by integrating a novel attention-based CNN backbone, dataset augmentation using GANs,
      and a domain adaptation module. Results show significant gains in accuracy and robustness under diverse FOD scenarios.
    </p>

    <h2>1. Introduction</h2>
    <p>
      Foreign Object Debris on runways can lead to severe accidents. Manual detection is time-consuming and error-prone.
      We propose a robust, scalable deep learning framework for real-time visual FOD detection...
    </p>

    <h2>2. Related Work</h2>
    <p>
      We categorize prior approaches into classical vision pipelines, deep object detectors (YOLO, Faster R-CNN), and
      recent domain-adaptive architectures. However, existing systems lack robustness under poor lighting and occlusions...
    </p>

    <h2>3. Methodology</h2>
    <p>
      Our model uses an attention-enhanced ResNet-50 as the backbone. A GAN-augmented data loader increases minority FOD categories.
      We further apply domain-adversarial training using gradient reversal layers to handle variation across datasets.
    </p>

    <p>Mathematically, the loss function is given by:</p>
    <p>
      \[
        \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{cls}} + \lambda \mathcal{L}_{\text{domain}} + \beta \mathcal{L}_{\text{gan}}
      \]
    </p>

    <h2>4. Results</h2>
    <p>
      The following table shows performance across metrics:
    </p>

    <table>
      <tr>
        <th>Model</th>
        <th>mAP (%)</th>
        <th>F1-Score</th>
        <th>FPS</th>
      </tr>
      <tr>
        <td>YOLOv5</td>
        <td>72.4</td>
        <td>0.78</td>
        <td>45</td>
      </tr>
      <tr>
        <td>Ours</td>
        <td><strong>83.1</strong></td>
        <td><strong>0.87</strong></td>
        <td><strong>52</strong></td>
      </tr>
    </table>

    <h2>5. Qualitative Results</h2>
    <p>
      Below are sample detections under varying FOD types. Red boxes denote true positives; yellow boxes denote domain-adapted inferences.
    </p>
    <img src="assets/figures/sample_results.png" alt="Qualitative Results" style="width:100%; max-width:800px;">

    <h2>6. Conclusion</h2>
    <p>
      Our deep learning-based FOD detection system outperforms conventional models and achieves real-time inference speed.
      Future work includes deployment on edge devices and integration with airport CCTV systems.
    </p>

    <h2>References</h2>
    <ul>
      <li>[1] Redmon et al. "YOLOv3: An Incremental Improvement", arXiv, 2018</li>
      <li>[2] Ganin et al. "Domain-Adversarial Training of Neural Networks", JMLR, 2016</li>
      <li>[3] Isola et al. "Image-to-Image Translation with Conditional GANs", CVPR 2017</li>
    </ul>
  </div>

  <footer class="container blog">
    <p>
      Built using the <a href="https://shikun.io/projects/clarity" target="_blank">Clarity Template</a> ·
      Licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
    </p>
  </footer>
</body>

</html>
